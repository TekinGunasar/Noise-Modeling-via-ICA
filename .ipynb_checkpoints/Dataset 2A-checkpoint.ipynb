{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e13dbd-63c2-4da0-809a-597348122356",
   "metadata": {},
   "source": [
    "# Loading A01T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd41d8de-f8b6-4fae-8c33-cc63728c57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab25bc-ea90-4de8-b4ca-adacb46babaa",
   "metadata": {},
   "source": [
    "For training segment, as done in the FBCSP algorithm only using data of each trial in between 0.5 and 2.5 seconds after cue onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac320dd2-dd9e-48b4-bbda-43233ad7fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fs = 250\n",
    "\n",
    "data = np.load('Dataset 2A/A01T.npz')\n",
    "signals = data['s']\n",
    "\n",
    "eeg = signals.T[:-3]\n",
    "\n",
    "n_trials = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44c851f-fbad-4217-870e-f65bfb205976",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = data['etyp']\n",
    "event_durations = data['edur']\n",
    "event_positions = data['epos']\n",
    "\n",
    "training_trials = {\n",
    "    769: [],\n",
    "    770: [],\n",
    "    771: [],\n",
    "    772: []\n",
    "}\n",
    "\n",
    "cue_onset_codes = [769,770,771,772]\n",
    "\n",
    "for i in range(len(event_types)):\n",
    "\n",
    "    event_code = event_types[i][0]\n",
    "    event_position = event_positions[i][0]\n",
    "\n",
    "    if event_code in cue_onset_codes:\n",
    "\n",
    "        start_idx = event_position + int(0.5*fs)\n",
    "        end_idx = start_idx + int(2*fs)\n",
    "\n",
    "        cur_trial = eeg[:,start_idx:end_idx]\n",
    "        training_trials[event_code].append(cur_trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c36877-c325-491a-97a8-cbab6e23a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = np.ones((n_trials,len(eeg),fs*2))\n",
    "labels = np.array([1]*72 + [2]*72 + [3]*72 + [4]*72)\n",
    "\n",
    "idx_counter = 0\n",
    "\n",
    "for class_label in training_trials:\n",
    "    for trial in training_trials[class_label]:\n",
    "        trials[idx_counter] = trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cefcadb-6be9-45d9-9cdc-c471f867babf",
   "metadata": {},
   "source": [
    "# Filter Banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b08d441-c3fb-4f90-b850-fc21b9913e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbcsp_code.bin.MLEngine import FilterBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db52f239-0deb-4541-8372-315eba44aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bank = FilterBank(fs)\n",
    "filter_coefs = filter_bank.get_filter_coeff()\n",
    "\n",
    "filter_bank_trials = filter_bank.filter_data(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d8f03-ab5f-4aaf-98e2-d99e1e62d059",
   "metadata": {},
   "source": [
    "# Approach 1 - Divide and Conquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b708b3-50a4-4355-86fc-0d741ac54691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = set(labels)\n",
    "\n",
    "\n",
    "#i.e different datasets for the classifiers\n",
    "\n",
    "'''\n",
    "    class one versus class 2,3,4\n",
    "    class two versus 3,4\n",
    "    class three versus 4\n",
    "\n",
    "    if we get past classifier for class three versus 4, then auto assign class 4 as prediction\n",
    "'''\n",
    "\n",
    "divide_and_conquer_datasets = {\n",
    "    0:{\n",
    "        'class_one_trials':[],\n",
    "        'class_two_trials':[]\n",
    "    },\n",
    "    1:{\n",
    "        'class_one_trials':[],\n",
    "        'class_two_trials':[]\n",
    "    },\n",
    "    2:{\n",
    "        'class_one_trials':[],\n",
    "        'class_two_trials':[]\n",
    "    }\n",
    "}\n",
    "\n",
    "possible_label_combinations = [\n",
    "    [[1],[2,3,4]], [[2],[3,4]], [[3],[4]]\n",
    "]\n",
    "\n",
    "for i,label_combination in enumerate(possible_label_combinations):\n",
    "\n",
    "    class_one_labels = label_combination[0]\n",
    "    class_two_labels = label_combination[1]\n",
    "\n",
    "    for j,label in enumerate(labels):\n",
    "        \n",
    "        cur_trial = filter_bank_trials[:,j]\n",
    "        if label in class_one_labels:\n",
    "            divide_and_conquer_datasets[i]['class_one_trials'].append(cur_trial)\n",
    "\n",
    "        elif label in class_two_labels:\n",
    "            divide_and_conquer_datasets[i]['class_two_trials'].append(cur_trial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e802d-080a-4d95-871c-1f013576ea54",
   "metadata": {},
   "source": [
    "Now that we have each of the datasets, we fit CSP to each one and get joint diagonalization of the covariance matrices for the combined class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2f931d-e51f-4844-85e4-55c045954e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbcsp_code.bin.CSP import CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcd7bb9-7765-410a-838e-811e46abf52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_feature_vecs = {\n",
    "    0:{\n",
    "        'class_one_trials':[],\n",
    "        'class_two_trials':[]\n",
    "    },\n",
    "    1:{\n",
    "        'class_one_trials':[],\n",
    "        'class_two_trials':[]\n",
    "    },\n",
    "    2:{\n",
    "        'class_one_trials':[],\n",
    "        'class_two_trials':[]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "for key in divide_and_conquer_datasets:\n",
    "\n",
    "    class_one_trials = divide_and_conquer_datasets[key]['class_one_trials']\n",
    "    class_two_trials = divide_and_conquer_datasets[key]['class_two_trials']\n",
    "    \n",
    "    \n",
    "    class_labels = [0]*len(class_one_trials) + [1]*len(class_two_trials)\n",
    "    class_trials = np.concatenate((class_one_trials,class_two_trials)).transpose(1,0,2,3)\n",
    "    \n",
    "    n_trials = class_trials.shape[1]\n",
    "    \n",
    "    csp_projection_matrices = []\n",
    "    \n",
    "    for i,frequency_band in enumerate(class_trials):\n",
    "        cur_trials = class_trials[i]\n",
    "        \n",
    "        cur_csp_filter = CSP(m_filters = 2)\n",
    "        cur_eig_vals,cur_eig_vectors = cur_csp_filter.fit(cur_trials,class_labels)\n",
    "        csp_projection_matrices.append(cur_eig_vectors)\n",
    "    \n",
    "    \n",
    "    \n",
    "    csp_filter = CSP(m_filters = 2)\n",
    "    V_bar = []\n",
    "    for i in range(n_trials):\n",
    "    \n",
    "        v_i = np.array([])\n",
    "        for j,projection_matrix in enumerate(csp_projection_matrices):\n",
    "    \n",
    "            cur_trial = class_trials[j][i]\n",
    "            v_b_i = csp_filter.transform(cur_trial,projection_matrix)\n",
    "            v_i = np.concatenate((v_i,v_b_i))\n",
    "    \n",
    "\n",
    "        cur_label = class_labels[i]\n",
    "\n",
    "        if cur_label == 0:\n",
    "            initial_feature_vecs[key]['class_one_trials'].append(v_i)\n",
    "        elif cur_label == 1:\n",
    "            initial_feature_vecs[key]['class_two_trials'].append(v_i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5269a44-4795-468f-943f-00bcced59e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbcsp_code.bin.Classifier import FeatureSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "426213d8-3eee-4356-b650-cda4599c4bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 8)\n"
     ]
    }
   ],
   "source": [
    "feature_selector = FeatureSelect()\n",
    "\n",
    "class_one_trials = initial_feature_vecs[0]['class_one_trials']\n",
    "class_two_trials = initial_feature_vecs[0]['class_two_trials']\n",
    "\n",
    "train_trials = np.concatenate((class_one_trials,class_two_trials))\n",
    "train_labels = [0]*len(class_one_trials) + [1]*len(class_two_trials)\n",
    "\n",
    "training_features = feature_selector.fit(train_trials,train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
